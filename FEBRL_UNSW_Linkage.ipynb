{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce results of Scheme A\n",
    "\n",
    "Paper: \"Statistical supervised meta-ensemble algorithm for data linkage\"\n",
    "\n",
    "Kha Vo, Jitendra Jonnagaddala, Siaw-Teng Liaw\n",
    "\n",
    "February 2019\n",
    "\n",
    "Jounal of Biomedical Informatics\n",
    "\n",
    "Paper: \"Statistical supervised meta-ensemble algorithm for data linkage\"\n",
    "\n",
    "Kha Vo, Jitendra Jonnagaddala, Siaw-Teng Liaw\n",
    "\n",
    "February 2019\n",
    "\n",
    "Jounal of Biomedical Informatics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import recordlinkage as rl, pandas as pd, numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from recordlinkage.preprocessing import phonetic\n",
    "from numpy.random import choice\n",
    "import collections, numpy\n",
    "from IPython.display import clear_output\n",
    "from sklearn.model_selection import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import (\n",
    "    generate_true_links,\n",
    "    generate_false_links,\n",
    "    swap_fields_flag,\n",
    "    join_names_space,\n",
    "    join_names_dash,\n",
    "    abb_surname,\n",
    "    reset_day,\n",
    "    set_random_seed\n",
    ")\n",
    "from training_utils import train_model, classify, evaluation, blocking_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = 'febrl_UNSW_train'\n",
    "testset = 'febrl_UNSW_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I did not touch these yet b/c there are differences\n",
    "## - Andrew\n",
    "def extract_features(df, links):\n",
    "    c = rl.Compare()\n",
    "    c.string('given_name', 'given_name', method='jarowinkler', label='y_name')\n",
    "    c.string('given_name_soundex', 'given_name_soundex', method='jarowinkler', label='y_name_soundex')\n",
    "    c.string('given_name_nysiis', 'given_name_nysiis', method='jarowinkler', label='y_name_nysiis')\n",
    "    c.string('surname', 'surname', method='jarowinkler', label='y_surname')\n",
    "    c.string('surname_soundex', 'surname_soundex', method='jarowinkler', label='y_surname_soundex')\n",
    "    c.string('surname_nysiis', 'surname_nysiis', method='jarowinkler', label='y_surname_nysiis')\n",
    "    c.exact('street_number', 'street_number', label='y_street_number')\n",
    "    c.string('address_1', 'address_1', method='levenshtein', threshold=0.7, label='y_address1')\n",
    "    c.string('address_2', 'address_2', method='levenshtein', threshold=0.7, label='y_address2')\n",
    "    c.exact('postcode', 'postcode', label='y_postcode')\n",
    "    c.exact('day', 'day', label='y_day')\n",
    "    c.exact('month', 'month', label='y_month')\n",
    "    c.exact('year', 'year', label='y_year')\n",
    "        \n",
    "    # Build features\n",
    "    feature_vectors = c.compute(links, df, df)\n",
    "    return feature_vectors\n",
    "\n",
    "\n",
    "def generate_train_X_y(df,train_true_links):\n",
    "    # This routine is to generate the feature vector X and the corresponding labels y\n",
    "    # with exactly equal number of samples for both classes to train the classifier.\n",
    "    pos = extract_features(df, train_true_links)\n",
    "    train_false_links = generate_false_links(df, len(train_true_links))    \n",
    "    neg = extract_features(df, train_false_links)\n",
    "    X = pos.values.tolist() + neg.values.tolist()\n",
    "    y = [1]*len(pos)+[0]*len(neg)\n",
    "    X, y = shuffle(X, y, random_state=0)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import train set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [00:00<00:00, 3462.50it/s]\n",
      "/Users/alecmori_1/Github/Medical-Record-Linkage-Ensemble/venv/lib/python3.9/site-packages/recordlinkage/preprocessing/encoding.py:80: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  s = s.str.replace(r\"[\\-\\_\\s]\", \"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 5000 , number of matched pairs:  1165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alecmori_1/Github/Medical-Record-Linkage-Ensemble/venv/lib/python3.9/site-packages/recordlinkage/preprocessing/encoding.py:80: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  s = s.str.replace(r\"[\\-\\_\\s]\", \"\")\n",
      "/Users/alecmori_1/Github/Medical-Record-Linkage-Ensemble/venv/lib/python3.9/site-packages/recordlinkage/preprocessing/encoding.py:80: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  s = s.str.replace(r\"[\\-\\_\\s]\", \"\")\n",
      "/Users/alecmori_1/Github/Medical-Record-Linkage-Ensemble/venv/lib/python3.9/site-packages/recordlinkage/preprocessing/encoding.py:80: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  s = s.str.replace(r\"[\\-\\_\\s]\", \"\")\n",
      "100%|██████████| 1165/1165 [00:00<00:00, 1291.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished building X_train, y_train\n"
     ]
    }
   ],
   "source": [
    "## TRAIN SET CONSTRUCTION\n",
    "\n",
    "# Import\n",
    "print(\"Import train set...\")\n",
    "df_train = pd.read_csv(trainset+\".csv\", index_col = \"rec_id\")\n",
    "train_true_links = generate_true_links(df_train)\n",
    "print(\"Train set size:\", len(df_train), \", number of matched pairs: \", str(len(train_true_links)))\n",
    "\n",
    "# Preprocess train set\n",
    "df_train['postcode'] = df_train['postcode'].astype(str)\n",
    "df_train['given_name_soundex'] = phonetic(df_train['given_name'], method='soundex')\n",
    "df_train['given_name_nysiis'] = phonetic(df_train['given_name'], method='nysiis')\n",
    "df_train['surname_soundex'] = phonetic(df_train['surname'], method='soundex')\n",
    "df_train['surname_nysiis'] = phonetic(df_train['surname'], method='nysiis')\n",
    "\n",
    "# Final train feature vectors and labels\n",
    "X_train, y_train = generate_train_X_y(df_train)\n",
    "print(\"Finished building X_train, y_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rec_id\n",
       "rec-1496-org      mitchell\n",
       "rec-552-dup-3       harley\n",
       "rec-988-dup-1     madeline\n",
       "rec-1716-dup-1    isabelle\n",
       "rec-1213-org        taylor\n",
       "Name: given_name, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['given_name'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:02<00:00, 2168.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set size: 10000 , number of matched pairs:  5000\n",
      "BLOCKING PERFORMANCE:\n",
      "Number of pairs of matched given_name: 154898 , detected  3287 /5000 true matched pairs, missed 1713\n",
      "Number of pairs of matched surname: 170843 , detected  3325 /5000 true matched pairs, missed 1675\n",
      "Number of pairs of matched postcode: 53197 , detected  4219 /5000 true matched pairs, missed 781\n",
      "Number of pairs of at least 1 field matched: 372073 , detected  4894 /5000 true matched pairs, missed 106\n"
     ]
    }
   ],
   "source": [
    "# Blocking Criteria: declare non-match of all of the below fields disagree\n",
    "# Import\n",
    "print(\"Import test set...\")\n",
    "df_test = pd.read_csv(testset+\".csv\", index_col = \"rec_id\")\n",
    "test_true_links = generate_true_links(df_test)\n",
    "leng_test_true_links = len(test_true_links)\n",
    "print(\"Test set size:\", len(df_test), \", number of matched pairs: \", str(leng_test_true_links))\n",
    "\n",
    "print(\"BLOCKING PERFORMANCE:\")\n",
    "blocking_fields = [\"given_name\", \"surname\", \"postcode\"]\n",
    "all_candidate_pairs = []\n",
    "for field in blocking_fields:\n",
    "    block_indexer = rl.BlockIndex(on=field)\n",
    "    candidates = block_indexer.index(df_test)\n",
    "    # Comment(alecmori): blocking_performance takes two arguments, I think it's these two\n",
    "    # detects = blocking_performance(candidates, test_true_links, df_test)\n",
    "    detects = blocking_performance(candidates, df_test)\n",
    "    all_candidate_pairs = candidates.union(all_candidate_pairs)\n",
    "    print(\"Number of pairs of matched \"+ field +\": \"+str(len(candidates)), \", detected \",\n",
    "         detects,'/'+ str(leng_test_true_links) + \" true matched pairs, missed \" + \n",
    "          str(leng_test_true_links-detects) )\n",
    "# Comment(alecmori): blocking_performance takes two arguments, I think it's these two\n",
    "# detects = blocking_performance(all_candidate_pairs, test_true_links, df_test)\n",
    "detects = blocking_performance(all_candidate_pairs, df_test)\n",
    "print(\"Number of pairs of at least 1 field matched: \" + str(len(all_candidate_pairs)), \", detected \",\n",
    "     detects,'/'+ str(leng_test_true_links) + \" true matched pairs, missed \" + \n",
    "          str(leng_test_true_links-detects) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test set...\n",
      "Preprocess...\n",
      "Extract feature vectors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alecmori_1/Github/Medical-Record-Linkage-Ensemble/venv/lib/python3.9/site-packages/recordlinkage/preprocessing/encoding.py:80: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  s = s.str.replace(r\"[\\-\\_\\s]\", \"\")\n",
      "/Users/alecmori_1/Github/Medical-Record-Linkage-Ensemble/venv/lib/python3.9/site-packages/recordlinkage/preprocessing/encoding.py:80: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  s = s.str.replace(r\"[\\-\\_\\s]\", \"\")\n",
      "/Users/alecmori_1/Github/Medical-Record-Linkage-Ensemble/venv/lib/python3.9/site-packages/recordlinkage/preprocessing/encoding.py:80: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  s = s.str.replace(r\"[\\-\\_\\s]\", \"\")\n",
      "/Users/alecmori_1/Github/Medical-Record-Linkage-Ensemble/venv/lib/python3.9/site-packages/recordlinkage/preprocessing/encoding.py:80: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  s = s.str.replace(r\"[\\-\\_\\s]\", \"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count labels of y_test: Counter({0: 367179, 1: 4894})\n",
      "Finished building X_test, y_test\n"
     ]
    }
   ],
   "source": [
    "## TEST SET CONSTRUCTION\n",
    "\n",
    "# Preprocess test set\n",
    "print(\"Processing test set...\")\n",
    "print(\"Preprocess...\")\n",
    "df_test['postcode'] = df_test['postcode'].astype(str)\n",
    "df_test['given_name_soundex'] = phonetic(df_test['given_name'], method='soundex')\n",
    "df_test['given_name_nysiis'] = phonetic(df_test['given_name'], method='nysiis')\n",
    "df_test['surname_soundex'] = phonetic(df_test['surname'], method='soundex')\n",
    "df_test['surname_nysiis'] = phonetic(df_test['surname'], method='nysiis')\n",
    "\n",
    "# Test feature vectors and labels construction\n",
    "print(\"Extract feature vectors...\")\n",
    "df_X_test = extract_features(df_test, all_candidate_pairs)\n",
    "vectors = df_X_test.values.tolist()\n",
    "labels = [0]*len(vectors)\n",
    "feature_index = df_X_test.index\n",
    "for i in range(0, len(feature_index)):\n",
    "    if df_test.loc[feature_index[i][0]][\"match_id\"]==df_test.loc[feature_index[i][1]][\"match_id\"]:\n",
    "        labels[i] = 1\n",
    "X_test, y_test = shuffle(vectors, labels, random_state=0)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "print(\"Count labels of y_test:\",collections.Counter(y_test))\n",
    "print(\"Finished building X_test, y_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE LEARNERS CLASSIFICATION PERFORMANCE:\n",
      "Model: svm , Param_1: rbf , tuning range: [0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1, 5, 10, 20, 50, 100, 200, 500, 1000, 2000, 5000]\n",
      "No_false: [149, 688, 2813, 3841, 6361, 5923, 5974, 3730, 5302, 5653, 11689, 11072, 12022, 11997, 11997, 11997, 11997, 11996, 11997, 11997] \n",
      "\n",
      "Precision: [0.974025974025974, 0.8789189189189189, 0.635217673814165, 0.5603576751117735, 0.43478260869565216, 0.4524095828323004, 0.45027624309392267, 0.5675644299976782, 0.4799725112900059, 0.46399089097637347, 0.29502262443438915, 0.30645363408521303, 0.28923713778829097, 0.28966538347645837, 0.28966538347645837, 0.28966538347645837, 0.28966538347645837, 0.2896825396825397, 0.28966538347645837, 0.28966538347645837] \n",
      "\n",
      "Sensitivity: [0.9961176951369023, 0.9967306906416019, 0.9987740089906008, 0.9987740089906008, 0.9991826726604005, 0.9993870044953004, 0.9991826726604005, 0.9989783408255006, 0.9989783408255006, 0.9991826726604005, 0.9991826726604005, 0.9993870044953004, 0.9993870044953004, 0.9993870044953004, 0.9993870044953004, 0.9993870044953004, 0.9993870044953004, 0.9993870044953004, 0.9993870044953004, 0.9993870044953004] \n",
      "\n",
      "F-score: [0.984947974542883, 0.934124856376867, 0.7765509571848439, 0.7179261217595654, 0.6059104144724615, 0.6228589621139764, 0.6207947188015742, 0.7238673378738526, 0.6484084880636605, 0.6337069915116957, 0.4555405468349713, 0.4690706818835715, 0.44863327829756006, 0.44914826208733183, 0.44914826208733183, 0.44914826208733183, 0.44914826208733183, 0.4491688860317752, 0.44914826208733183, 0.44914826208733183] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## BASE LEARNERS CLASSIFICATION AND EVALUATION\n",
    "# Choose model\n",
    "print(\"BASE LEARNERS CLASSIFICATION PERFORMANCE:\")\n",
    "modeltype = 'svm' # choose between 'svm', 'lg', 'nn'\n",
    "modeltype_2 = 'rbf'  # 'linear' or 'rbf' for svm, 'l1' or 'l2' for lg, 'relu' or 'logistic' for nn\n",
    "modelparam_range = [.001,.002,.005,.01,.02,.05,.1,.2,.5,1,5,10,20,50,100,200,500,1000,2000,5000] # C for svm, C for lg, alpha for NN\n",
    "print(\"Model:\",modeltype,\", Param_1:\",modeltype_2, \", tuning range:\", modelparam_range)\n",
    "precision = []\n",
    "sensitivity = []\n",
    "Fscore = []\n",
    "nb_false = []\n",
    "\n",
    "for modelparam in modelparam_range:\n",
    "    md = train_model(modeltype, modelparam, X_train, y_train, modeltype_2)\n",
    "    final_result = classify(md, X_test)\n",
    "    final_eval = evaluation(y_test, final_result)\n",
    "    precision += [final_eval['precision']]\n",
    "    sensitivity += [final_eval['sensitivity']]\n",
    "    Fscore += [final_eval['F-score']]\n",
    "    nb_false  += [final_eval['no_false']]\n",
    "    \n",
    "print(\"No_false:\",nb_false,\"\\n\")\n",
    "print(\"Precision:\",precision,\"\\n\")\n",
    "print(\"Sensitivity:\",sensitivity,\"\\n\")\n",
    "print(\"F-score:\", Fscore,\"\\n\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAGGING PERFORMANCE:\n",
      "\n",
      "svm per fold:\n",
      "Fold 0 {'no_false': 194, 'confusion_matrix': [4877, 177, 17, 367002], 'precision': 0.9649782350613375, 'sensitivity': 0.996526358806702, 'no_links': 5054, 'F-score': 0.9804985926819461}\n",
      "Fold 1 {'no_false': 245, 'confusion_matrix': [4878, 229, 16, 366950], 'precision': 0.9551595848834933, 'sensitivity': 0.9967306906416019, 'no_links': 5107, 'F-score': 0.9755024497550244}\n",
      "Fold 2 {'no_false': 269, 'confusion_matrix': [4877, 252, 17, 366927], 'precision': 0.9508676155195944, 'sensitivity': 0.996526358806702, 'no_links': 5129, 'F-score': 0.9731617280255411}\n",
      "Fold 3 {'no_false': 206, 'confusion_matrix': [4877, 189, 17, 366990], 'precision': 0.9626924595341493, 'sensitivity': 0.996526358806702, 'no_links': 5066, 'F-score': 0.9793172690763051}\n",
      "Fold 4 {'no_false': 192, 'confusion_matrix': [4877, 175, 17, 367004], 'precision': 0.965360253365004, 'sensitivity': 0.996526358806702, 'no_links': 5052, 'F-score': 0.9806957570882766}\n",
      "Fold 5 {'no_false': 227, 'confusion_matrix': [4877, 210, 17, 366969], 'precision': 0.9587183015529782, 'sensitivity': 0.996526358806702, 'no_links': 5087, 'F-score': 0.9772567878970043}\n",
      "Fold 6 {'no_false': 190, 'confusion_matrix': [4877, 173, 17, 367006], 'precision': 0.9657425742574257, 'sensitivity': 0.996526358806702, 'no_links': 5050, 'F-score': 0.9808930008045053}\n",
      "Fold 7 {'no_false': 230, 'confusion_matrix': [4877, 213, 17, 366966], 'precision': 0.9581532416502947, 'sensitivity': 0.996526358806702, 'no_links': 5090, 'F-score': 0.976963141025641}\n",
      "Fold 8 {'no_false': 189, 'confusion_matrix': [4877, 172, 17, 367007], 'precision': 0.9659338482867894, 'sensitivity': 0.996526358806702, 'no_links': 5049, 'F-score': 0.980991652418787}\n",
      "Fold 9 {'no_false': 203, 'confusion_matrix': [4877, 186, 17, 366993], 'precision': 0.963262887616038, 'sensitivity': 0.996526358806702, 'no_links': 5063, 'F-score': 0.9796123330320378}\n",
      "svm bagging: {'no_false': 207, 'confusion_matrix': [4877, 190, 17, 366989], 'precision': 0.9625024669429643, 'sensitivity': 0.996526358806702, 'no_links': 5067, 'F-score': 0.979218953920289}\n",
      "\n",
      "nn per fold:\n",
      "Fold 0 {'no_false': 158, 'confusion_matrix': [4876, 140, 18, 367039], 'precision': 0.9720893141945773, 'sensitivity': 0.9963220269718022, 'no_links': 5016, 'F-score': 0.9840565085771947}\n",
      "Fold 1 {'no_false': 178, 'confusion_matrix': [4876, 160, 18, 367019], 'precision': 0.9682287529785544, 'sensitivity': 0.9963220269718022, 'no_links': 5036, 'F-score': 0.982074521651561}\n",
      "Fold 2 {'no_false': 167, 'confusion_matrix': [4876, 149, 18, 367030], 'precision': 0.9703482587064677, 'sensitivity': 0.9963220269718022, 'no_links': 5025, 'F-score': 0.9831636253654602}\n",
      "Fold 3 {'no_false': 172, 'confusion_matrix': [4876, 154, 18, 367025], 'precision': 0.9693836978131213, 'sensitivity': 0.9963220269718022, 'no_links': 5030, 'F-score': 0.9826682789197904}\n",
      "Fold 4 {'no_false': 154, 'confusion_matrix': [4876, 136, 18, 367043], 'precision': 0.9728651237031125, 'sensitivity': 0.9963220269718022, 'no_links': 5012, 'F-score': 0.9844538663436302}\n",
      "Fold 5 {'no_false': 188, 'confusion_matrix': [4876, 170, 18, 367009], 'precision': 0.9663099484740388, 'sensitivity': 0.9963220269718022, 'no_links': 5046, 'F-score': 0.9810865191146881}\n",
      "Fold 6 {'no_false': 164, 'confusion_matrix': [4876, 146, 18, 367033], 'precision': 0.9709279171644764, 'sensitivity': 0.9963220269718022, 'no_links': 5022, 'F-score': 0.9834610730133119}\n",
      "Fold 7 {'no_false': 178, 'confusion_matrix': [4877, 161, 17, 367018], 'precision': 0.9680428741564113, 'sensitivity': 0.996526358806702, 'no_links': 5038, 'F-score': 0.9820781312927911}\n",
      "Fold 8 {'no_false': 165, 'confusion_matrix': [4876, 147, 18, 367032], 'precision': 0.970734620744575, 'sensitivity': 0.9963220269718022, 'no_links': 5023, 'F-score': 0.9833619038015529}\n",
      "Fold 9 {'no_false': 184, 'confusion_matrix': [4876, 166, 18, 367013], 'precision': 0.9670765569218565, 'sensitivity': 0.9963220269718022, 'no_links': 5042, 'F-score': 0.9814814814814815}\n",
      "nn bagging: {'no_false': 168, 'confusion_matrix': [4876, 150, 18, 367029], 'precision': 0.9701551929964186, 'sensitivity': 0.9963220269718022, 'no_links': 5026, 'F-score': 0.9830645161290322}\n",
      "\n",
      "lg per fold:\n",
      "Fold 0 {'no_false': 595, 'confusion_matrix': [4885, 586, 9, 366593], 'precision': 0.89288978248949, 'sensitivity': 0.9981610134859011, 'no_links': 5471, 'F-score': 0.9425952725518572}\n",
      "Fold 1 {'no_false': 720, 'confusion_matrix': [4885, 711, 9, 366468], 'precision': 0.8729449606862044, 'sensitivity': 0.9981610134859011, 'no_links': 5596, 'F-score': 0.9313632030505242}\n",
      "Fold 2 {'no_false': 607, 'confusion_matrix': [4885, 598, 9, 366581], 'precision': 0.8909356191865767, 'sensitivity': 0.9981610134859011, 'no_links': 5483, 'F-score': 0.9415052519996145}\n",
      "Fold 3 {'no_false': 706, 'confusion_matrix': [4886, 698, 8, 366481], 'precision': 0.875, 'sensitivity': 0.998365345320801, 'no_links': 5584, 'F-score': 0.9326207291467837}\n",
      "Fold 4 {'no_false': 585, 'confusion_matrix': [4885, 576, 9, 366603], 'precision': 0.8945248123054386, 'sensitivity': 0.9981610134859011, 'no_links': 5461, 'F-score': 0.9435055528730082}\n",
      "Fold 5 {'no_false': 778, 'confusion_matrix': [4885, 769, 9, 366410], 'precision': 0.8639900955076052, 'sensitivity': 0.9981610134859011, 'no_links': 5654, 'F-score': 0.9262419416003034}\n",
      "Fold 6 {'no_false': 634, 'confusion_matrix': [4885, 625, 9, 366554], 'precision': 0.8865698729582577, 'sensitivity': 0.9981610134859011, 'no_links': 5510, 'F-score': 0.9390618992695118}\n",
      "Fold 7 {'no_false': 680, 'confusion_matrix': [4885, 671, 9, 366508], 'precision': 0.8792296616270698, 'sensitivity': 0.9981610134859011, 'no_links': 5556, 'F-score': 0.9349282296650717}\n",
      "Fold 8 {'no_false': 660, 'confusion_matrix': [4886, 652, 8, 366527], 'precision': 0.8822679667750091, 'sensitivity': 0.998365345320801, 'no_links': 5538, 'F-score': 0.9367331288343558}\n",
      "Fold 9 {'no_false': 694, 'confusion_matrix': [4885, 685, 9, 366494], 'precision': 0.8770197486535009, 'sensitivity': 0.9981610134859011, 'no_links': 5570, 'F-score': 0.9336773700305809}\n",
      "lg bagging: {'no_false': 638, 'confusion_matrix': [4885, 629, 9, 366550], 'precision': 0.8859267319550236, 'sensitivity': 0.9981610134859011, 'no_links': 5514, 'F-score': 0.9387009992313605}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## ENSEMBLE CLASSIFICATION AND EVALUATION\n",
    "\n",
    "print(\"BAGGING PERFORMANCE:\\n\")\n",
    "modeltypes = ['svm', 'nn', 'lg'] \n",
    "modeltypes_2 = ['linear', 'relu', 'l2']\n",
    "modelparams = [0.005, 100, 0.2]\n",
    "nFold = 10\n",
    "kf = KFold(n_splits=nFold)\n",
    "model_raw_score = [0]*3\n",
    "model_binary_score = [0]*3\n",
    "model_i = 0\n",
    "for model_i in range(3):\n",
    "    modeltype = modeltypes[model_i]\n",
    "    modeltype_2 = modeltypes_2[model_i]\n",
    "    modelparam = modelparams[model_i]\n",
    "    print(modeltype, \"per fold:\")\n",
    "    iFold = 0\n",
    "    result_fold = [0]*nFold\n",
    "    final_eval_fold = [0]*nFold\n",
    "    for train_index, valid_index in kf.split(X_train):\n",
    "        X_train_fold = X_train[train_index]\n",
    "        y_train_fold = y_train[train_index]\n",
    "        md =  train_model(modeltype, modelparam, X_train_fold, y_train_fold, modeltype_2)\n",
    "        result_fold[iFold] = classify(md, X_test)\n",
    "        final_eval_fold[iFold] = evaluation(y_test, result_fold[iFold])\n",
    "        print(\"Fold\", str(iFold), final_eval_fold[iFold])\n",
    "        iFold = iFold + 1\n",
    "    bagging_raw_score = np.average(result_fold, axis=0)\n",
    "    bagging_binary_score  = np.copy(bagging_raw_score)\n",
    "    bagging_binary_score[bagging_binary_score > 0.5] = 1\n",
    "    bagging_binary_score[bagging_binary_score <= 0.5] = 0\n",
    "    bagging_eval = evaluation(y_test, bagging_binary_score)\n",
    "    print(modeltype, \"bagging:\", bagging_eval)\n",
    "    print('')\n",
    "    model_raw_score[model_i] = bagging_raw_score\n",
    "    model_binary_score[model_i] = bagging_binary_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STACKING PERFORMANCE:\n",
      "\n",
      "{'no_false': 120, 'confusion_matrix': [4875, 101, 19, 367078], 'precision': 0.9797025723472669, 'sensitivity': 0.9961176951369023, 'no_links': 4976, 'F-score': 0.9878419452887538}\n"
     ]
    }
   ],
   "source": [
    "thres = .99\n",
    "\n",
    "print(\"STACKING PERFORMANCE:\\n\")\n",
    "stack_raw_score = np.average(model_raw_score, axis=0)\n",
    "stack_binary_score = np.copy(stack_raw_score)\n",
    "stack_binary_score[stack_binary_score > thres] = 1\n",
    "stack_binary_score[stack_binary_score <= thres] = 0\n",
    "stacking_eval = evaluation(y_test, stack_binary_score)\n",
    "print(stacking_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
