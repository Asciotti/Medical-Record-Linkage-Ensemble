{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce results of Scheme B\n",
    "\n",
    "Paper: \"Statistical supervised meta-ensemble algorithm for data linkage\"\n",
    "\n",
    "Kha Vo, Jitendra Jonnagaddala, Siaw-Teng Liaw\n",
    "\n",
    "February 2019\n",
    "\n",
    "Jounal of Biomedical Informatics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import recordlinkage as rl, pandas as pd, numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from recordlinkage.preprocessing import phonetic\n",
    "from numpy.random import choice\n",
    "import collections, numpy\n",
    "from IPython.display import clear_output\n",
    "from sklearn.model_selection import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import (\n",
    "    generate_true_links,\n",
    "    generate_false_links,\n",
    "    swap_fields_flag,\n",
    "    join_names_space,\n",
    "    join_names_dash,\n",
    "    abb_surname,\n",
    "    reset_day\n",
    ")\n",
    "from training_utils import train_model, classify, evaluation, blocking_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = 'ePBRN_dup_train' \n",
    "testset = 'ePBRN_dup_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I did not touch these yet b/c there are differences\n",
    "## - Andrew\n",
    "def extract_features(df, links):\n",
    "    c = rl.Compare()\n",
    "    c.string('given_name', 'given_name', method='levenshtein', label='y_name_leven')\n",
    "    c.string('surname', 'surname', method='levenshtein', label='y_surname_leven')  \n",
    "    c.string('given_name', 'given_name', method='jarowinkler', label='y_name_jaro')\n",
    "    c.string('surname', 'surname', method='jarowinkler', label='y_surname_jaro')  \n",
    "    c.string('postcode', 'postcode', method='jarowinkler', label='y_postcode')      \n",
    "    exact_fields = ['postcode', 'address_1', 'address_2', 'street_number']\n",
    "    for field in exact_fields:\n",
    "        c.exact(field, field, label='y_'+field+'_exact')\n",
    "    c.compare_vectorized(reset_day,('day', 'month'), ('day', 'month'),label='reset_day_flag')    \n",
    "    c.compare_vectorized(swap_fields_flag,('day', 'month'), ('day', 'month'),label='swap_day_month')    \n",
    "    c.compare_vectorized(swap_fields_flag,('surname', 'given_name'), ('surname', 'given_name'),label='swap_names')    \n",
    "    c.compare_vectorized(join_names_space,('surname', 'given_name'), ('surname', 'given_name'),label='join_names_space')\n",
    "    c.compare_vectorized(join_names_dash,('surname', 'given_name'), ('surname', 'given_name'),label='join_names_dash')\n",
    "    c.compare_vectorized(abb_surname,'surname', 'surname',label='abb_surname')\n",
    "    # Build features\n",
    "    feature_vectors = c.compute(links, df, df)\n",
    "    return feature_vectors\n",
    "\n",
    "def generate_train_X_y(df):\n",
    "    # This routine is to generate the feature vector X and the corresponding labels y\n",
    "    # with exactly equal number of samples for both classes to train the classifier.\n",
    "    pos = extract_features(df, train_true_links)\n",
    "    train_false_links = generate_false_links(df, len(train_true_links))    \n",
    "    neg = extract_features(df, train_false_links)\n",
    "    X = pos.values.tolist() + neg.values.tolist()\n",
    "    y = [1]*len(pos)+[0]*len(neg)\n",
    "    X, y = shuffle(X, y, random_state=0)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import train set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11101/11101 [00:02<00:00, 3867.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 14078 , number of matched pairs:  3192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3192/3192 [00:02<00:00, 1409.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished building X_train, y_train\n"
     ]
    }
   ],
   "source": [
    "## TRAIN SET CONSTRUCTION\n",
    "\n",
    "# Import\n",
    "print(\"Import train set...\")\n",
    "df_train = pd.read_csv(trainset+\".csv\", index_col = \"rec_id\")\n",
    "train_true_links = generate_true_links(df_train)\n",
    "print(\"Train set size:\", len(df_train), \", number of matched pairs: \", str(len(train_true_links)))\n",
    "\n",
    "# Preprocess train set\n",
    "df_train['postcode'] = df_train['postcode'].astype(str)\n",
    "\n",
    "# Final train feature vectors and labels\n",
    "X_train, y_train = generate_train_X_y(df_train)\n",
    "print(\"Finished building X_train, y_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9251/9251 [00:02<00:00, 3801.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set size: 11731 , number of matched pairs:  2653\n",
      "BLOCKING PERFORMANCE:\n",
      "Number of pairs of matched given_name: 252552 , detected  1567 /2653 true matched pairs, missed 1086\n",
      "Number of pairs of matched surname: 33832 , detected  1480 /2653 true matched pairs, missed 1173\n",
      "Number of pairs of matched postcode: 79940 , detected  2462 /2653 true matched pairs, missed 191\n",
      "Number of pairs of at least 1 field matched: 362910 , detected  2462 /2653 true matched pairs, missed 191\n"
     ]
    }
   ],
   "source": [
    "# Blocking Criteria: declare non-match of all of the below fields disagree\n",
    "# Import\n",
    "print(\"Import test set...\")\n",
    "df_test = pd.read_csv(testset+\".csv\", index_col = \"rec_id\")\n",
    "test_true_links = generate_true_links(df_test)\n",
    "leng_test_true_links = len(test_true_links)\n",
    "print(\"Test set size:\", len(df_test), \", number of matched pairs: \", str(leng_test_true_links))\n",
    "\n",
    "print(\"BLOCKING PERFORMANCE:\")\n",
    "blocking_fields = [\"given_name\", \"surname\", \"postcode\"]\n",
    "all_candidate_pairs = []\n",
    "for field in blocking_fields:\n",
    "    block_indexer = rl.BlockIndex(on=field)\n",
    "    candidates = block_indexer.index(df_test)\n",
    "    # Comment(alecmori): This only takes two arguments, I think it's these two.\n",
    "    # detects = blocking_performance(candidates, test_true_links, df_test)\n",
    "    detects = blocking_performance(candidates, df_test)\n",
    "    all_candidate_pairs = candidates.union(all_candidate_pairs)\n",
    "    print(\"Number of pairs of matched \"+ field +\": \"+str(len(candidates)), \", detected \",\n",
    "         detects,'/'+ str(leng_test_true_links) + \" true matched pairs, missed \" + \n",
    "          str(leng_test_true_links-detects) )\n",
    "\n",
    "# Comment(alecmori): This only takes two arguments, I think it's these two.\n",
    "# detects = blocking_performance(candidates, test_true_links, df_test)\n",
    "detects = blocking_performance(candidates, df_test)\n",
    "print(\"Number of pairs of at least 1 field matched: \" + str(len(all_candidate_pairs)), \", detected \",\n",
    "     detects,'/'+ str(leng_test_true_links) + \" true matched pairs, missed \" + \n",
    "          str(leng_test_true_links-detects) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test set...\n",
      "Preprocess...\n",
      "Extract feature vectors...\n",
      "Count labels of y_test: Counter({0: 360311, 1: 2599})\n",
      "Finished building X_test, y_test\n"
     ]
    }
   ],
   "source": [
    "## TEST SET CONSTRUCTION\n",
    "\n",
    "# Preprocess test set\n",
    "print(\"Processing test set...\")\n",
    "print(\"Preprocess...\")\n",
    "df_test['postcode'] = df_test['postcode'].astype(str)\n",
    "\n",
    "# Test feature vectors and labels construction\n",
    "print(\"Extract feature vectors...\")\n",
    "df_X_test = extract_features(df_test, all_candidate_pairs)\n",
    "vectors = df_X_test.values.tolist()\n",
    "labels = [0]*len(vectors)\n",
    "feature_index = df_X_test.index\n",
    "for i in range(0, len(feature_index)):\n",
    "    if df_test.loc[feature_index[i][0]][\"match_id\"]==df_test.loc[feature_index[i][1]][\"match_id\"]:\n",
    "        labels[i] = 1\n",
    "X_test, y_test = shuffle(vectors, labels, random_state=0)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "print(\"Count labels of y_test:\",collections.Counter(y_test))\n",
    "print(\"Finished building X_test, y_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE LEARNERS CLASSIFICATION PERFORMANCE:\n",
      "Model: svm , Param_1: rbf , tuning range: [0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1, 5, 10, 20, 50, 100, 200, 500, 1000, 2000, 5000]\n",
      "No_false: [5510, 9152, 66398, 81753, 81363, 78959, 78301, 78417, 83173, 89356, 89874, 88159, 88619, 84546, 85709, 85474, 85354, 82259, 100198, 129548] \n",
      "\n",
      "Precision: [0.31890008709717554, 0.22012471171094217, 0.037587881423497865, 0.03080023710729105, 0.030943306336350642, 0.031855412232085926, 0.03211451457390788, 0.03206853136494927, 0.03030126381569743, 0.028263824696862595, 0.02810550106517578, 0.02862620653179955, 0.028481845290299946, 0.02979148257381884, 0.029388448471121178, 0.029477556860117864, 0.029528476730832642, 0.030616573960592062, 0.025264366250620177, 0.01963114040730454] \n",
      "\n",
      "Sensitivity: [0.9861485186610235, 0.9915352058484033, 0.9976914197768373, 0.9996152366294728, 0.9996152366294728, 0.9996152366294728, 0.9996152366294728, 0.9996152366294728, 1.0, 1.0, 1.0, 0.9996152366294728, 0.9996152366294728, 0.9988457098884186, 0.9984609465178915, 0.9988457098884186, 0.9992304732589458, 0.9996152366294728, 0.9992304732589458, 0.9980761831473643] \n",
      "\n",
      "F-score: [0.4819481007897706, 0.3602684188452398, 0.0724463567277604, 0.059759169168133036, 0.06002841992167192, 0.061743211930366575, 0.06222978071068421, 0.0621434465932331, 0.058820201197225336, 0.05497387736108467, 0.05467435207001009, 0.055658507846392806, 0.05538559931780632, 0.05785731797009071, 0.05709633769348398, 0.05726512694946286, 0.05736184123337898, 0.05941341261220055, 0.049282678002125394, 0.03850492815580097] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## BASE LEARNERS CLASSIFICATION AND EVALUATION\n",
    "# Choose model\n",
    "print(\"BASE LEARNERS CLASSIFICATION PERFORMANCE:\")\n",
    "modeltype = 'svm' # choose between 'svm', 'lg', 'nn'\n",
    "modeltype_2 = 'rbf'  # 'linear' or 'rbf' for svm, 'l1' or 'l2' for lg, 'relu' or 'logistic' for nn\n",
    "modelparam_range = [.001,.002,.005,.01,.02,.05,.1,.2,.5,1,5,10,20,50,100,200,500,1000,2000,5000] # C for svm, C for lg, alpha for NN\n",
    "\n",
    "print(\"Model:\",modeltype,\", Param_1:\",modeltype_2, \", tuning range:\", modelparam_range)\n",
    "precision = []\n",
    "sensitivity = []\n",
    "Fscore = []\n",
    "nb_false = []\n",
    "\n",
    "for modelparam in modelparam_range:\n",
    "    md = train_model(modeltype, modelparam, X_train, y_train, modeltype_2)\n",
    "    final_result = classify(md, X_test)\n",
    "    final_eval = evaluation(y_test, final_result)\n",
    "    precision += [final_eval['precision']]\n",
    "    sensitivity += [final_eval['sensitivity']]\n",
    "    Fscore += [final_eval['F-score']]\n",
    "    nb_false  += [final_eval['no_false']]\n",
    "    \n",
    "print(\"No_false:\",nb_false,\"\\n\")\n",
    "print(\"Precision:\",precision,\"\\n\")\n",
    "print(\"Sensitivity:\",sensitivity,\"\\n\")\n",
    "print(\"F-score:\", Fscore,\"\\n\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAGGING PERFORMANCE:\n",
      "\n",
      "svm per fold:\n",
      "Fold 0 {'no_false': 4581, 'confusion_matrix': [2550, 4532, 49, 355779], 'precision': 0.3600677774639932, 'sensitivity': 0.9811465948441709, 'no_links': 7082, 'F-score': 0.5268050821196157}\n",
      "Fold 1 {'no_false': 4485, 'confusion_matrix': [2550, 4436, 49, 355875], 'precision': 0.3650157457772688, 'sensitivity': 0.9811465948441709, 'no_links': 6986, 'F-score': 0.5320813771517997}\n",
      "Fold 2 {'no_false': 4561, 'confusion_matrix': [2552, 4514, 47, 355797], 'precision': 0.3611661477497877, 'sensitivity': 0.9819161215852251, 'no_links': 7066, 'F-score': 0.5280910501810657}\n",
      "Fold 3 {'no_false': 4620, 'confusion_matrix': [2552, 4573, 47, 355738], 'precision': 0.3581754385964912, 'sensitivity': 0.9819161215852251, 'no_links': 7125, 'F-score': 0.5248868778280542}\n",
      "Fold 4 {'no_false': 4576, 'confusion_matrix': [2550, 4527, 49, 355784], 'precision': 0.3603221704111912, 'sensitivity': 0.9811465948441709, 'no_links': 7077, 'F-score': 0.5270773046713518}\n",
      "Fold 5 {'no_false': 4544, 'confusion_matrix': [2550, 4495, 49, 355816], 'precision': 0.36195883605393897, 'sensitivity': 0.9811465948441709, 'no_links': 7045, 'F-score': 0.5288262131895479}\n",
      "Fold 6 {'no_false': 4654, 'confusion_matrix': [2552, 4607, 47, 355704], 'precision': 0.35647436792848164, 'sensitivity': 0.9819161215852251, 'no_links': 7159, 'F-score': 0.5230580036892806}\n",
      "Fold 7 {'no_false': 4424, 'confusion_matrix': [2550, 4375, 49, 355936], 'precision': 0.36823104693140796, 'sensitivity': 0.9811465948441709, 'no_links': 6925, 'F-score': 0.5354892902141958}\n",
      "Fold 8 {'no_false': 4568, 'confusion_matrix': [2550, 4519, 49, 355792], 'precision': 0.3607299476587919, 'sensitivity': 0.9811465948441709, 'no_links': 7069, 'F-score': 0.5275134464211833}\n",
      "Fold 9 {'no_false': 4469, 'confusion_matrix': [2550, 4420, 49, 355891], 'precision': 0.36585365853658536, 'sensitivity': 0.9811465948441709, 'no_links': 6970, 'F-score': 0.532971052356568}\n",
      "svm bagging: {'no_false': 4561, 'confusion_matrix': [2550, 4512, 49, 355799], 'precision': 0.3610875106202209, 'sensitivity': 0.9811465948441709, 'no_links': 7062, 'F-score': 0.5278956629748472}\n",
      "\n",
      "nn per fold:\n",
      "Fold 0 {'no_false': 1205, 'confusion_matrix': [2507, 1113, 92, 359198], 'precision': 0.6925414364640884, 'sensitivity': 0.9646017699115044, 'no_links': 3620, 'F-score': 0.8062389451680335}\n",
      "Fold 1 {'no_false': 1062, 'confusion_matrix': [2506, 969, 93, 359342], 'precision': 0.7211510791366906, 'sensitivity': 0.9642170065409773, 'no_links': 3475, 'F-score': 0.8251564043463944}\n",
      "Fold 2 {'no_false': 1255, 'confusion_matrix': [2507, 1163, 92, 359148], 'precision': 0.6831062670299728, 'sensitivity': 0.9646017699115044, 'no_links': 3670, 'F-score': 0.7998085819109906}\n",
      "Fold 3 {'no_false': 1054, 'confusion_matrix': [2506, 961, 93, 359350], 'precision': 0.7228151139313528, 'sensitivity': 0.9642170065409773, 'no_links': 3467, 'F-score': 0.8262446422683811}\n",
      "Fold 4 {'no_false': 1112, 'confusion_matrix': [2506, 1019, 93, 359292], 'precision': 0.7109219858156028, 'sensitivity': 0.9642170065409773, 'no_links': 3525, 'F-score': 0.8184193337687786}\n",
      "Fold 5 {'no_false': 1022, 'confusion_matrix': [2506, 929, 93, 359382], 'precision': 0.7295487627365357, 'sensitivity': 0.9642170065409773, 'no_links': 3435, 'F-score': 0.8306264501160093}\n",
      "Fold 6 {'no_false': 1144, 'confusion_matrix': [2507, 1052, 92, 359259], 'precision': 0.7044113515032312, 'sensitivity': 0.9646017699115044, 'no_links': 3559, 'F-score': 0.8142253978564468}\n",
      "Fold 7 {'no_false': 1276, 'confusion_matrix': [2510, 1187, 89, 359124], 'precision': 0.6789288612388423, 'sensitivity': 0.9657560600230858, 'no_links': 3697, 'F-score': 0.7973316391359594}\n",
      "Fold 8 {'no_false': 1174, 'confusion_matrix': [2507, 1082, 92, 359229], 'precision': 0.6985232655335748, 'sensitivity': 0.9646017699115044, 'no_links': 3589, 'F-score': 0.8102779573367808}\n",
      "Fold 9 {'no_false': 1157, 'confusion_matrix': [2507, 1065, 92, 359246], 'precision': 0.7018477043673013, 'sensitivity': 0.9646017699115044, 'no_links': 3572, 'F-score': 0.8125101280181494}\n",
      "nn bagging: {'no_false': 1128, 'confusion_matrix': [2507, 1036, 92, 359275], 'precision': 0.7075924357888794, 'sensitivity': 0.9646017699115044, 'no_links': 3543, 'F-score': 0.8163464669488766}\n",
      "\n",
      "lg per fold:\n",
      "Fold 0 {'no_false': 1698, 'confusion_matrix': [2511, 1610, 88, 358701], 'precision': 0.6093181266682844, 'sensitivity': 0.966140823393613, 'no_links': 4121, 'F-score': 0.7473214285714287}\n",
      "Fold 1 {'no_false': 1749, 'confusion_matrix': [2511, 1661, 88, 358650], 'precision': 0.6018696069031639, 'sensitivity': 0.966140823393613, 'no_links': 4172, 'F-score': 0.7416925121843154}\n",
      "Fold 2 {'no_false': 1759, 'confusion_matrix': [2517, 1677, 82, 358634], 'precision': 0.600143061516452, 'sensitivity': 0.9684494036167757, 'no_links': 4194, 'F-score': 0.7410569704107168}\n",
      "Fold 3 {'no_false': 1742, 'confusion_matrix': [2517, 1660, 82, 358651], 'precision': 0.6025855877423989, 'sensitivity': 0.9684494036167757, 'no_links': 4177, 'F-score': 0.7429161747343566}\n",
      "Fold 4 {'no_false': 1731, 'confusion_matrix': [2511, 1643, 88, 358668], 'precision': 0.6044776119402985, 'sensitivity': 0.966140823393613, 'no_links': 4154, 'F-score': 0.7436694802310084}\n",
      "Fold 5 {'no_false': 1708, 'confusion_matrix': [2511, 1620, 88, 358691], 'precision': 0.6078431372549019, 'sensitivity': 0.966140823393613, 'no_links': 4131, 'F-score': 0.7462109955423477}\n",
      "Fold 6 {'no_false': 1753, 'confusion_matrix': [2511, 1665, 88, 358646], 'precision': 0.6012931034482759, 'sensitivity': 0.966140823393613, 'no_links': 4176, 'F-score': 0.7412546125461256}\n",
      "Fold 7 {'no_false': 1725, 'confusion_matrix': [2511, 1637, 88, 358674], 'precision': 0.6053519768563163, 'sensitivity': 0.966140823393613, 'no_links': 4148, 'F-score': 0.7443308136949757}\n",
      "Fold 8 {'no_false': 1694, 'confusion_matrix': [2511, 1606, 88, 358705], 'precision': 0.6099101287345154, 'sensitivity': 0.966140823393613, 'no_links': 4117, 'F-score': 0.7477665276950566}\n",
      "Fold 9 {'no_false': 1733, 'confusion_matrix': [2512, 1646, 87, 358665], 'precision': 0.6041366041366041, 'sensitivity': 0.96652558676414, 'no_links': 4158, 'F-score': 0.7435252330916087}\n",
      "lg bagging: {'no_false': 1728, 'confusion_matrix': [2511, 1640, 88, 358671], 'precision': 0.6049144784389304, 'sensitivity': 0.966140823393613, 'no_links': 4151, 'F-score': 0.7440000000000001}\n",
      "\n",
      "STACKING PERFORMANCE:\n",
      "\n",
      "{'no_false': 1011, 'confusion_matrix': [2505, 917, 94, 359394], 'precision': 0.7320280537697254, 'sensitivity': 0.9638322431704501, 'no_links': 3422, 'F-score': 0.8320876930742402}\n"
     ]
    }
   ],
   "source": [
    "## ENSEMBLE CLASSIFICATION AND EVALUATION\n",
    "\n",
    "print(\"BAGGING PERFORMANCE:\\n\")\n",
    "modeltypes = ['svm', 'nn', 'lg'] \n",
    "modeltypes_2 = ['rbf', 'relu', 'l2']\n",
    "modelparams = [0.001, 2000, 0.005]\n",
    "nFold = 10\n",
    "kf = KFold(n_splits=nFold)\n",
    "model_raw_score = [0]*3\n",
    "model_binary_score = [0]*3\n",
    "model_i = 0\n",
    "for model_i in range(3):\n",
    "    modeltype = modeltypes[model_i]\n",
    "    modeltype_2 = modeltypes_2[model_i]\n",
    "    modelparam = modelparams[model_i]\n",
    "    print(modeltype, \"per fold:\")\n",
    "    iFold = 0\n",
    "    result_fold = [0]*nFold\n",
    "    final_eval_fold = [0]*nFold\n",
    "    for train_index, valid_index in kf.split(X_train):\n",
    "        X_train_fold = X_train[train_index]\n",
    "        y_train_fold = y_train[train_index]\n",
    "        md =  train_model(modeltype, modelparam, X_train_fold, y_train_fold, modeltype_2)\n",
    "        result_fold[iFold] = classify(md, X_test)\n",
    "        final_eval_fold[iFold] = evaluation(y_test, result_fold[iFold])\n",
    "        print(\"Fold\", str(iFold), final_eval_fold[iFold])\n",
    "        iFold = iFold + 1\n",
    "    bagging_raw_score = np.average(result_fold, axis=0)\n",
    "    bagging_binary_score  = np.copy(bagging_raw_score)\n",
    "    bagging_binary_score[bagging_binary_score > 0.5] = 1\n",
    "    bagging_binary_score[bagging_binary_score <= 0.5] = 0\n",
    "    bagging_eval = evaluation(y_test, bagging_binary_score)\n",
    "    print(modeltype, \"bagging:\", bagging_eval)\n",
    "    print('')\n",
    "    model_raw_score[model_i] = bagging_raw_score\n",
    "    model_binary_score[model_i] = bagging_binary_score\n",
    "    \n",
    "thres = .99\n",
    "print(\"STACKING PERFORMANCE:\\n\")\n",
    "stack_raw_score = np.average(model_raw_score, axis=0)\n",
    "stack_binary_score = np.copy(stack_raw_score)\n",
    "stack_binary_score[stack_binary_score > thres] = 1\n",
    "stack_binary_score[stack_binary_score <= thres] = 0\n",
    "stacking_eval = evaluation(y_test, stack_binary_score)\n",
    "print(stacking_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
